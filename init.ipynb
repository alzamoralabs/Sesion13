{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "073f9b51",
   "metadata": {},
   "source": [
    "### ChromaDB Vector Embeddings con LangChain\n",
    "Ref> https://airbyte.com/data-engineering-resources/chroma-db-vector-embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f594bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-community pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0516a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"./data/openaiguide.pdf\"\n",
    "loader = PyPDFLoader(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a2a1ec",
   "metadata": {},
   "source": [
    "Extract the PDF by page. Each page is extracted as a langchain Document object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83b36476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "{'producer': 'pdf-lib (https://github.com/Hopding/pdf-lib)',\n",
      " 'creator': 'pdf-lib (https://github.com/Hopding/pdf-lib)',\n",
      " 'creationdate': '2025-04-07T14:20:51+00:00',\n",
      " 'moddate': '2025-04-07T14:20:54+00:00',\n",
      " 'source': './data/openaiguide.pdf',\n",
      " 'total_pages': 34,\n",
      " 'page': 0,\n",
      " 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "file_path = \"./data/openaiguide.pdf\"\n",
    "loader = PyPDFLoader(\n",
    "    file_path,\n",
    "    mode=\"page\",  ## Cargar por página, tambien puede ser entero usando \"single\"\n",
    ")\n",
    "docs = loader.load()\n",
    "print(len(docs))\n",
    "\n",
    "pprint.pp(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e8470a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "\n",
    "# Chunking Básico sin solapamiento\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "documents = text_splitter.split_documents(docs)\n",
    "\n",
    "# Chunking Semántico con solapamiento\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,  # Mantenemos contexto entre chunks\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"] # Definimos separadores jerárquicos\n",
    ")\n",
    "documents = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a696219",
   "metadata": {},
   "source": [
    "Embed text and store in ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a90feb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "db = Chroma.from_documents(documents, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b738c69e",
   "metadata": {},
   "source": [
    "Similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3bf450f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A s y ou e v alua t e wher e agen ts can add v alue ,  prioritiz e w orkflo w s tha t ha v e pr e viously  r esist ed \n",
      "aut oma tion,  especially  wher e tr aditional me thods encoun t er  fric tion:\n",
      "01 C o m p l e x   \n",
      "d e c i s i o n - m a k i n g :  \n",
      "W orkflo w s in v olving nuanced judgmen t,  e x cep tions,  or   \n",
      "con t e xt -sensitiv e decisions,  f or  e x ample r e fund appr o v al  \n",
      "in cust omer  service w orkflo w s.\n",
      "02 D i ffi c u l t - t o - m a i n t a i n  \n",
      "r u l e s :\n",
      "S y st ems tha t ha v e become unwieldy  due t o e xt ensiv e and \n",
      "in trica t e rulese ts,  making upda t es costly  or  err or -pr one ,   \n",
      "f or  e x ample perf orming v endor  security  r e vie w s.  \n",
      "03 H e a v y  r e l i a n c e  o n  \n",
      "u n s t r u c t u r e d  d a t a :\n",
      "Scenarios tha t in v olv e in t erpr e ting na tur al language ,   \n",
      "e xtr ac ting meaning fr om documen ts,  or  in t er ac ting with  \n",
      "user s con v er sa tionally ,  f or  e x ample pr ocessing a home \n",
      "insur ance claim.\n"
     ]
    }
   ],
   "source": [
    "query = \"workflow definition\"\n",
    "docs = db.similarity_search(query)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ab4852",
   "metadata": {},
   "source": [
    "Advanced RAG Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0446c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autonomous agents are systems that independently accomplish tasks on behalf of users with a high degree of independence. Unlike conventional software that requires user input to streamline and automate workflows, autonomous agents can perform these workflows autonomously, making decisions and handling complexity without direct user intervention. They are particularly suited for workflows where traditional deterministic and rule-based approaches may fall short, allowing them to manage complex and ambiguous situations effectively.\n",
      "page_content='W h a t  i s  a n  \n",
      "a g e n t ?\n",
      "While con v en tional so ftw ar e enables user s t o str eamline and aut oma t e w orkflo w s,  agen ts ar e able \n",
      "t o perf orm the same w orkflo w s on the user s ’  behalf  with a high degr ee o f  independence .\n",
      "A gen ts ar e s y st ems tha t independen tly accomplish task s on y our  behalf .\n",
      "A  w orkflo w  is a sequence o f  st eps tha t must be e x ecut ed t o mee t the user’ s goal,  whe ther  tha t ' s \n",
      "r esolving a cust omer  service issue ,  booking a r estaur an t r eserv a tion,  committing a code change ,   \n",
      "or  gener a ting a r eport.\n",
      "Applica tions tha t in t egr a t e LLM s but don ’t use them t o con tr ol w orkflo w  e x ecution— think  simple \n",
      "cha tbo ts,  single- turn LLM s,  or  sen timen t classifier s—ar e no t agen ts.\n",
      "M or e concr e t ely ,  an agen t possesses cor e char ac t eristics tha t allo w  it t o ac t r eliably  and \n",
      "consist en tly  on behalf  o f  a user:' metadata={'creationdate': '2025-04-07T14:20:51+00:00', 'page': 3, 'producer': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'source': './data/openaiguide.pdf', 'creator': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'total_pages': 34, 'moddate': '2025-04-07T14:20:54+00:00', 'page_label': '4'}\n",
      "---\n",
      "\n",
      "\n",
      "page_content='W h a t  i s  a n  \n",
      "a g e n t ?\n",
      "While con v en tional so ftw ar e enables user s t o str eamline and aut oma t e w orkflo w s,  agen ts ar e able \n",
      "t o perf orm the same w orkflo w s on the user s ’  behalf  with a high degr ee o f  independence .\n",
      "A gen ts ar e s y st ems tha t independen tly accomplish task s on y our  behalf .\n",
      "A  w orkflo w  is a sequence o f  st eps tha t must be e x ecut ed t o mee t the user’ s goal,  whe ther  tha t ' s \n",
      "r esolving a cust omer  service issue ,  booking a r estaur an t r eserv a tion,  committing a code change ,   \n",
      "or  gener a ting a r eport.\n",
      "Applica tions tha t in t egr a t e LLM s but don ’t use them t o con tr ol w orkflo w  e x ecution— think  simple \n",
      "cha tbo ts,  single- turn LLM s,  or  sen timen t classifier s—ar e no t agen ts.\n",
      "M or e concr e t ely ,  an agen t possesses cor e char ac t eristics tha t allo w  it t o ac t r eliably  and \n",
      "consist en tly  on behalf  o f  a user:' metadata={'creationdate': '2025-04-07T14:20:51+00:00', 'total_pages': 34, 'creator': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'page_label': '4', 'source': './data/openaiguide.pdf', 'moddate': '2025-04-07T14:20:54+00:00', 'page': 3, 'producer': 'pdf-lib (https://github.com/Hopding/pdf-lib)'}\n",
      "---\n",
      "\n",
      "\n",
      "page_content='W h e n  s h o u l d  y o u  \n",
      "b u i l d  a n  a g e n t ?\n",
      "Building agen ts r equir es r e thinking ho w  y our  s y st ems mak e decisions and handle comple xity .  \n",
      "U nlik e con v en tional aut oma tion,  agen ts ar e uniquely  suit ed t o w orkflo w s wher e tr aditional \n",
      "de t erministic and rule-based appr oaches f all short.\n",
      "Consider  the e x ample o f  pa ymen t fr aud analy sis.  A  tr aditional rules engine w ork s lik e a checklist,  \n",
      "flagging tr ansac tions based on pr ese t crit eria.  I n con tr ast,  an LLM agen t func tions mor e lik e a \n",
      "seasoned in v estiga t or ,  e v alua ting con t e xt,  considering sub tle pa tt erns,  and iden tifying suspicious \n",
      "ac tivity  e v en when clear -cut rules ar en ’t viola t ed.  This nuanced r easoning capability  is e x ac tly  wha t \n",
      "enables agen ts t o manage comple x,  ambiguous situa tions e ff ec tiv ely .' metadata={'moddate': '2025-04-07T14:20:54+00:00', 'page': 4, 'source': './data/openaiguide.pdf', 'page_label': '5', 'creator': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'total_pages': 34, 'producer': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'creationdate': '2025-04-07T14:20:51+00:00'}\n",
      "---\n",
      "\n",
      "\n",
      "page_content='W h e n  s h o u l d  y o u  \n",
      "b u i l d  a n  a g e n t ?\n",
      "Building agen ts r equir es r e thinking ho w  y our  s y st ems mak e decisions and handle comple xity .  \n",
      "U nlik e con v en tional aut oma tion,  agen ts ar e uniquely  suit ed t o w orkflo w s wher e tr aditional \n",
      "de t erministic and rule-based appr oaches f all short.\n",
      "Consider  the e x ample o f  pa ymen t fr aud analy sis.  A  tr aditional rules engine w ork s lik e a checklist,  \n",
      "flagging tr ansac tions based on pr ese t crit eria.  I n con tr ast,  an LLM agen t func tions mor e lik e a \n",
      "seasoned in v estiga t or ,  e v alua ting con t e xt,  considering sub tle pa tt erns,  and iden tifying suspicious \n",
      "ac tivity  e v en when clear -cut rules ar en ’t viola t ed.  This nuanced r easoning capability  is e x ac tly  wha t \n",
      "enables agen ts t o manage comple x,  ambiguous situa tions e ff ec tiv ely .' metadata={'source': './data/openaiguide.pdf', 'page': 4, 'creationdate': '2025-04-07T14:20:51+00:00', 'moddate': '2025-04-07T14:20:54+00:00', 'creator': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'page_label': '5', 'producer': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'total_pages': 34}\n",
      "---\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Create retriever with custom parameters\n",
    "retriever = db.as_retriever(\n",
    "search_type=\"similarity_score_threshold\",\n",
    "search_kwargs={\"score_threshold\": 0.7, \"k\": 4}\n",
    ")\n",
    "\n",
    "llm=ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n",
    "\n",
    "# See full prompt at https://smith.langchain.com/hub/langchain-ai/retrieval-qa-chat\n",
    "retrieval_qa_chat_prompt = hub.pull(\"langchain-ai/retrieval-qa-chat\")\n",
    "\n",
    "combine_docs_chain = create_stuff_documents_chain(llm, retrieval_qa_chat_prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, combine_docs_chain)\n",
    "\n",
    "result = rag_chain.invoke({\"input\": \"What are autonomous agents?\"})\n",
    "\n",
    "print(result['answer'])\n",
    "for document in result['context']:\n",
    "    print(document)\n",
    "    print('---\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616a3844",
   "metadata": {},
   "source": [
    "#### Ahora probemos con una web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f583c8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load docs\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\"https://github.com/chiphuyen/aie-book/blob/main/chapter-summaries.md\")\n",
    "data = loader.load()\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "\n",
    "# Store splits\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "# LLM\n",
    "llm=ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadd0cd6",
   "metadata": {},
   "source": [
    "Y usando un mecanismo abreviado LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4108647d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- RAG (Retrieval-Augmented Generation) combines retrieval of relevant documents with generative capabilities to enhance response accuracy.  \\n- It is particularly useful for tasks like extracting meaning from documents or engaging in conversational interactions, such as processing home insurance claims.  \\n- Before implementing RAG, ensure your use case meets specific criteria; otherwise, a simpler deterministic solution may be more appropriate.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# See full prompt at https://smith.langchain.com/hub/rlm/rag-prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "qa_chain = (\n",
    "    {\n",
    "        \"context\": vectorstore.as_retriever() | format_docs,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "qa_chain.invoke(\"Define RAG en 3 bullets como si fueras Chip Huyen, con referencias a los documentos usados.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
